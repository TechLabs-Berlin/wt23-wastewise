{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6bdM22ZRJPxf"
      },
      "source": [
        "# Deploy the Fastai Classifier using Gradio and Hugging Face Spaces"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jC_GSmA68_35"
      },
      "source": [
        "# Preparations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VGa9Mfdz2A84",
        "outputId": "c7580931-0258-428a-c9f0-ff9a03b729f3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "# connect colab to google drive by mounting\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YMAkq_eq6h_7",
        "outputId": "f73795ea-2f13-44e6-c969-99592feccc86"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Errno 2] No such file or directory: 'drive/MyDrive/wt23-wastewise/'\n",
            "/content/drive/MyDrive/wt23-wastewise\n"
          ]
        }
      ],
      "source": [
        "# navigate to WasteWise directory\n",
        "%cd drive/MyDrive/wt23-wastewise/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "znQpIppX84-s",
        "outputId": "edbce3a7-d0cc-44fb-dc19-3a6efb93e9a8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "remote: Enumerating objects: 32, done.\u001b[K\n",
            "remote: Counting objects:   3% (1/32)\u001b[K\rremote: Counting objects:   6% (2/32)\u001b[K\rremote: Counting objects:   9% (3/32)\u001b[K\rremote: Counting objects:  12% (4/32)\u001b[K\rremote: Counting objects:  15% (5/32)\u001b[K\rremote: Counting objects:  18% (6/32)\u001b[K\rremote: Counting objects:  21% (7/32)\u001b[K\rremote: Counting objects:  25% (8/32)\u001b[K\rremote: Counting objects:  28% (9/32)\u001b[K\rremote: Counting objects:  31% (10/32)\u001b[K\rremote: Counting objects:  34% (11/32)\u001b[K\rremote: Counting objects:  37% (12/32)\u001b[K\rremote: Counting objects:  40% (13/32)\u001b[K\rremote: Counting objects:  43% (14/32)\u001b[K\rremote: Counting objects:  46% (15/32)\u001b[K\rremote: Counting objects:  50% (16/32)\u001b[K\rremote: Counting objects:  53% (17/32)\u001b[K\rremote: Counting objects:  56% (18/32)\u001b[K\rremote: Counting objects:  59% (19/32)\u001b[K\rremote: Counting objects:  62% (20/32)\u001b[K\rremote: Counting objects:  65% (21/32)\u001b[K\rremote: Counting objects:  68% (22/32)\u001b[K\rremote: Counting objects:  71% (23/32)\u001b[K\rremote: Counting objects:  75% (24/32)\u001b[K\rremote: Counting objects:  78% (25/32)\u001b[K\rremote: Counting objects:  81% (26/32)\u001b[K\rremote: Counting objects:  84% (27/32)\u001b[K\rremote: Counting objects:  87% (28/32)\u001b[K\rremote: Counting objects:  90% (29/32)\u001b[K\rremote: Counting objects:  93% (30/32)\u001b[K\rremote: Counting objects:  96% (31/32)\u001b[K\rremote: Counting objects: 100% (32/32)\u001b[K\rremote: Counting objects: 100% (32/32), done.\u001b[K\n",
            "remote: Compressing objects: 100% (13/13), done.\u001b[K\n",
            "remote: Total 32 (delta 19), reused 31 (delta 18), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (32/32), 6.39 MiB | 401.00 KiB/s, done.\n",
            "From https://github.com/TechLabs-Berlin/wt23-wastewise\n",
            "   8239cd4..d16396d  classifier_fastai      -> origin/classifier_fastai\n",
            "   6d8b0ff..4c6ee67  wd-frontend-crftwrks-2 -> origin/wd-frontend-crftwrks-2\n",
            "Already up to date.\n"
          ]
        }
      ],
      "source": [
        "# get latest version of branch\n",
        "!git pull"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "al7SccCO4g1O"
      },
      "outputs": [],
      "source": [
        "# install the fastbook library\n",
        "!pip install -Uqq fastbook"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "sn-GZDYfJPBO"
      },
      "outputs": [],
      "source": [
        "# install gradio\n",
        "!pip install -Uqq gradio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "Cv-hq5EB4iMx"
      },
      "outputs": [],
      "source": [
        "# import libraries\n",
        "# fastbook/fastai related libraries: used for training the classifier\n",
        "from fastbook import *\n",
        "from fastai.vision.widgets import *\n",
        "\n",
        "# import gradio for deployment \n",
        "import gradio as gr"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# disable warnings\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "oRPQYT7wemhW"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load the model"
      ],
      "metadata": {
        "id": "cyTnZ8ButXzl"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "id": "af0hV7CCKk0o"
      },
      "outputs": [],
      "source": [
        "# load the model\n",
        "learn = load_learner('/content/drive/MyDrive/wastewise_models/waste_recogniser_fastai_v2.pkl', cpu=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# test model inference on banana peel and see how long it takes\n",
        "%time learn.predict(\"/content/drive/MyDrive/wt23-wastewise/AI/data_20_classes/banana_peels/10_175867801.jpg\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 146
        },
        "id": "mfrjSyQ1OZki",
        "outputId": "72f43ed9-9b5f-458d-874b-2a643c829b78"
      },
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
              "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 410 ms, sys: 9.95 ms, total: 420 ms\n",
            "Wall time: 427 ms\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('banana_peels',\n",
              " tensor(2),\n",
              " tensor([5.1117e-05, 1.8186e-03, 9.7781e-01, 1.1703e-04, 4.7139e-04, 3.4299e-05, 8.4459e-04, 3.7959e-04, 1.2728e-04, 7.4091e-05, 8.2790e-05, 1.5245e-04, 1.0221e-04, 1.7327e-04, 1.0396e-02, 2.2642e-04,\n",
              "         2.3036e-04, 2.7148e-04, 2.5266e-05, 6.6162e-03]))"
            ]
          },
          "metadata": {},
          "execution_count": 103
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The fine tuned network has 101 layers and I was concerned it would take too long for inference, but this is definitely reasonable."
      ],
      "metadata": {
        "id": "z-d1PVG1OsbU"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OH1TAERzKsOE"
      },
      "source": [
        "# Trying out Gradio\n",
        "\n",
        "Make the most basic gradio app in the world."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "26E7k6YKKvb2"
      },
      "outputs": [],
      "source": [
        "def greet(name):\n",
        "    return \"Hello \" + name + \"!\"\n",
        "\n",
        "demo = gr.Interface(fn=greet, inputs=\"text\", outputs=\"text\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "VaY2iTXhK9c7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 621
        },
        "outputId": "793e164c-4b5a-4ab1-daec-be544c84258a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "Note: opening Chrome Inspector may crash demo inside Colab notebooks.\n",
            "\n",
            "To create a public link, set `share=True` in `launch()`.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "(async (port, path, width, height, cache, element) => {\n",
              "                        if (!google.colab.kernel.accessAllowed && !cache) {\n",
              "                            return;\n",
              "                        }\n",
              "                        element.appendChild(document.createTextNode(''));\n",
              "                        const url = await google.colab.kernel.proxyPort(port, {cache});\n",
              "\n",
              "                        const external_link = document.createElement('div');\n",
              "                        external_link.innerHTML = `\n",
              "                            <div style=\"font-family: monospace; margin-bottom: 0.5rem\">\n",
              "                                Running on <a href=${new URL(path, url).toString()} target=\"_blank\">\n",
              "                                    https://localhost:${port}${path}\n",
              "                                </a>\n",
              "                            </div>\n",
              "                        `;\n",
              "                        element.appendChild(external_link);\n",
              "\n",
              "                        const iframe = document.createElement('iframe');\n",
              "                        iframe.src = new URL(path, url).toString();\n",
              "                        iframe.height = height;\n",
              "                        iframe.allow = \"autoplay; camera; microphone; clipboard-read; clipboard-write;\"\n",
              "                        iframe.width = width;\n",
              "                        iframe.style.border = 0;\n",
              "                        element.appendChild(iframe);\n",
              "                    })(7861, \"/\", \"100%\", 500, false, window.element)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "source": [
        "demo.launch()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is the most basic gradio app ever, but it demonstrates that it works in Colab, which was the goal right here. Now scale it up!"
      ],
      "metadata": {
        "id": "TUGKOuIwc4fE"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "65WcXx-rLNew"
      },
      "source": [
        "# Make a gradio app that can be used in an API for the real app.\n",
        "\n",
        "In this case, I keep the outputs minimal, because the rest will be solved in JavaScript and HTML together with our WebDev."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# make a \"list\" containing the classes the classifier can distinguish\n",
        "# note that actual data type is not \"list\", but \"fastai.data.transforms.CategoryMap\"\n",
        "# it still works in a comparable way\n",
        "labels = learn.dls.vocab"
      ],
      "metadata": {
        "id": "M07zLAeEdJtI"
      },
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# see labels\n",
        "print(type(labels))\n",
        "print(labels)\n",
        "print(\"Label at index 2: \" + labels[2])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pZysg9nKdUwG",
        "outputId": "dbfab005-6b3d-4f62-fdcd-82b216e37235"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'fastai.data.transforms.CategoryMap'>\n",
            "['aluminum_foil', 'apples', 'banana_peels', 'cardboard', 'condoms', 'diapers', 'food_waste', 'glass_bottle', 'old_books', 'oranges', 'pans', 'pizza_box', 'plastic_bags', 'plastic_packaging', 'plastic_toys', 'smartphone', 'tampons', 'tea_bags', 'tetrapack', 'toothbrush']\n",
            "Label at index 2: banana_peels\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# make dictionaries translating the class to something else for the output\n",
        "\n",
        "# adapt class spelling for output\n",
        "spelling_dict = {\n",
        "    \"aluminum_foil\": \"aluminum foil\",\n",
        "    \"apples\": \"an apple\",\n",
        "    \"banana_peels\": \"a banana peel\",\n",
        "    \"cardboard\": \"cardboard\",\n",
        "    \"condoms\": \"a condom\",\n",
        "    \"diapers\": \"a diaper\",\n",
        "    \"food_waste\": \"food waste\",\n",
        "    \"glass_bottle\": \"a glass bottle\",\n",
        "    \"old_books\": \"a book\",\n",
        "    \"oranges\": \"an orange\",\n",
        "    \"pans\": \"a pan\",\n",
        "    \"pizza_box\": \"a pizza box\",\n",
        "    \"plastic_bags\": \"a plastic bag\",\n",
        "    \"plastic_packaging\": \"plastic packaging\",\n",
        "    \"plastic_toys\": \"a plastic toy\",\n",
        "    \"smartphone\": \"a smartphone\",\n",
        "    \"tampons\": \"a tampon\",\n",
        "    \"tea_bags\": \"a tea bag\",\n",
        "    \"tetrapack\": \"a tetra pak\",\n",
        "    \"toothbrush\": \"a toothbrush\"\n",
        "    }\n",
        "\n",
        "    # recommend waste bin for each class\n",
        "bin_dict = {\n",
        "    \"aluminum_foil\": \"gelbe sack\",\n",
        "    \"apples\": \"bio waste\",\n",
        "    \"banana_peels\": \"bio waste\",\n",
        "    \"cardboard\": \"paper waste\",\n",
        "    \"condoms\": \"residual waste\",\n",
        "    \"diapers\": \"residual waste\",\n",
        "    \"food_waste\": \"residual waste\",\n",
        "    \"glass_bottle\": \"glass waste\",\n",
        "    \"old_books\": \"paper waste\",\n",
        "    \"oranges\": \"bio waste\",\n",
        "    \"pans\": \"residual waste\",\n",
        "    \"pizza_box\": \"residual waste\",\n",
        "    \"plastic_bags\": \"plastic waste\",\n",
        "    \"plastic_packaging\": \"plastic waste\",\n",
        "    \"plastic_toys\": \"residual waste\",\n",
        "    \"smartphone\": \"wertstoffsammlung\",\n",
        "    \"tampons\": \"residual waste\",\n",
        "    \"tea_bags\": \"bio waste\",\n",
        "    \"tetrapack\": \"plastic waste\",\n",
        "    \"toothbrush\": \"residual waste\"}"
      ],
      "metadata": {
        "id": "hJVnxjr30jCY"
      },
      "execution_count": 111,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# define a function for the learner\n",
        "def predict(img):\n",
        "    img = PILImage.create(img)\n",
        "    pred,pred_idx,probs = learn.predict(img)\n",
        "\n",
        "    return {labels[i]: float(probs[i]) for i in range(len(labels))}"
      ],
      "metadata": {
        "id": "F1IE-C-5k0nU"
      },
      "execution_count": 118,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# make a gradio interface\n",
        "gr.Interface(fn=predict, inputs=gr.inputs.Image(shape=(512, 512)), outputs=gr.outputs.Label(num_top_classes=3)).launch(share=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 615
        },
        "id": "AvGD7VakirDA",
        "outputId": "127aa337-cc0b-476b-c035-6709d8dd20bf"
      },
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "Running on public URL: https://e78b04af3c4537b587.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades (NEW!), check out Spaces: https://huggingface.co/spaces\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://e78b04af3c4537b587.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 119
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Make a proper gradio website that can be shown off as a standalone."
      ],
      "metadata": {
        "id": "54CqcuaD0JW4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# define a function for the learner\n",
        "def predict(img):\n",
        "    img = PILImage.create(img)\n",
        "    pred,pred_idx,probs = learn.predict(img)\n",
        "\n",
        "    return {labels[i]: float(probs[i]) for i in range(len(labels))}, f'It belongs into the {bin_dict[pred]}.'"
      ],
      "metadata": {
        "id": "bbLKQVbw0ON1"
      },
      "execution_count": 122,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# make a gradio interface\n",
        "gr.Interface(fn=predict, inputs=gr.inputs.Image(shape=(512, 512)), outputs=[gr.outputs.Label(num_top_classes=3), \"text\"]).launch(share=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 615
        },
        "id": "du6jWgHM1yWT",
        "outputId": "4fc0fa8c-1c89-4ccc-b196-c6801b4a9a6f"
      },
      "execution_count": 123,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "Running on public URL: https://a808bc5cb41c100b09.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades (NEW!), check out Spaces: https://huggingface.co/spaces\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://a808bc5cb41c100b09.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 123
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "jC_GSmA68_35"
      ]
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}