{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "meb-oTjngGeh"
      },
      "source": [
        "# How to Deploy the ML Models\n",
        "\n",
        "Here, the TensorFlow model is converted to TensorFlow.js.\n",
        "The model fine tuned for distinguishing 20 classes is used here.\n",
        "\n",
        "Also, a brief tutorial is included for the WebDevs on how to use the model in JavaScript.\n",
        "\n",
        "TLDR version: The converted model can be found here: 'wt23-wastewise/AI/MLOps/tensorflow_js/model.json'\n",
        "_\n",
        "## Sources\n",
        "\n",
        "This is based on the tensor flow documentation and especially this:\n",
        "https://www.tensorflow.org/js/tutorials/conversion/import_saved_model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6lqzVgOvgPxl"
      },
      "source": [
        "# Preparations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MoX1NERBc460",
        "outputId": "87fffce4-a349-47e7-e764-0872e2176b5b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# connect colab to google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0__j7UNfdhiY",
        "outputId": "0e7b0da6-ef3c-4bc4-f6a6-edd3d65b5854"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/wt23-wastewise\n"
          ]
        }
      ],
      "source": [
        "# navigate to WasteWise Git repository and get updates\n",
        "%cd drive/MyDrive/wt23-wastewise"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4ULkAdrCfqUd"
      },
      "outputs": [],
      "source": [
        "# install libraries, packages, dependencies\n",
        "!pip install tensorflowjs # tensorflow to javascript converter\n",
        "!pip install pyyaml h5py  # required to save models in HDF5 format"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tiCN_F4NHAtT"
      },
      "outputs": [],
      "source": [
        "# load libraries, packages, dependencies\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q1BypxgtgrLj"
      },
      "source": [
        "# Converting the Model\n",
        "\n",
        "Use the TensorFlow.js converter to convert the model from Python to JavaScript.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B_TRGof3R-YU"
      },
      "outputs": [],
      "source": [
        "# optional: have a look at the model first\n",
        "# this is just for getting an overview and is not necessary for the conversion itself\n",
        "\n",
        "# load saved_model \n",
        "model = tf.keras.models.load_model('wt23-wastewise/AI/MLOps/tensorflow_js/model.json')\n",
        "\n",
        "# get a summary of the model including information about the layers etc.\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jl68oMlbZGYV"
      },
      "outputs": [],
      "source": [
        "# call the TensorFlow to JavaScript converter\n",
        "# it is a shell command, hence insert the exclamation mark if called in a Python environment\n",
        "!tensorflowjs_converter \\\n",
        "    --input_format=tf_saved_model \\          # format of the exported model. we used saved model format\n",
        "    --saved_model_tags=serve \\               # tags of MetaGraphDef to load, comma separated\n",
        "    AI/models/model_20_classes \\             # positional argument: input path\n",
        "    AI/MLOps/tensorflow_js   # positional argument: output path"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "37wpGXLijeX0"
      },
      "source": [
        "# Deploy in JavaScript and Inference/Integrate with App\n",
        "\n",
        "This is the previously mentioned tutorial part for the WebDevs.\n",
        "\n",
        "The file containing the converted model that you need is: \"wt23-wastewise/AI/MLOps/tensorflow_js/model.json\"."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WYBbNQ0Ix_N-"
      },
      "source": [
        "# Step 1: Install the tfjs-converter npm package\n",
        "This step is to be executed in the terminal.\n",
        "```bash\n",
        "yarn add @tensorflow/tfjs or npm install @tensorflow/tfjs\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zJvGXUBw0d3P"
      },
      "source": [
        "# Step 2: Load the dependencies\n",
        "\n",
        "From this step one, do in JavaScript.\n",
        "\n",
        "```javascript\n",
        "import * as tf from '@tensorflow/tfjs';\n",
        "import {loadGraphModel} from '@tensorflow/tfjs-converter';\n",
        "```"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "-sqGm9ly2AhT"
      },
      "source": [
        "# Step 3: Load the model\n",
        "\n",
        "```javascript\n",
        "// store absolute path to the TensorFlow.js model in variable \"MODEL_URL\"\n",
        "const MODEL_URL = 'wt23-wastewise/AI/MLOps/tensorflow_js/model.json';\n",
        "\n",
        "// load the model and store it as an object in variable \"model\"\n",
        "const model = await loadGraphModel(MODEL_URL);;\n",
        "```\n",
        "\n",
        "The loaded model is now callable using \"model\"."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B4K2l4a1MSCs"
      },
      "source": [
        "# Step 4: Get the image\n",
        "- Use the camera to take a photo.\n",
        "- Save that photo in a variable\n",
        "\n",
        "```javascript\n",
        "// example: call the variable \"waste\"\n",
        "// in place of \"...\", insert the code calling the camera\n",
        "const waste = ... ; \n",
        "```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d5FK0mSEkSn4"
      },
      "source": [
        "# Step 5: Query the model\n",
        "\n",
        "Use the method \"execute\" to query the model for inference.\n",
        "\n",
        "Try if this works already. There is a chance that \"tf.browser.fromPixels\" prepares the image in the desired way and that nothing else is necessary for this.\n",
        "\n",
        "```javascript\n",
        "// this is how you query the model: use the method \"execute\"\n",
        "model.execute(tf.browser.fromPixels(waste));\n",
        "```\n",
        "The input images need to be 224 x 224 normalised pixels in the correct file format. If querying the network does not work as intended, please follow the instructions below. There is a good chance that the problems are caused by the image not being correctly formatted."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c_VZpMBglBK5"
      },
      "source": [
        "# Step 6: Prepare images for being input to the algorithm\n",
        "\n",
        "If the instructions provided in step 5 do not just work like this, try these.\n",
        "\n",
        "## Image file format\n",
        "\n",
        "TensorFlow accepts jpeg, png, bmp (and gif, but that should not be relevant right here). \n",
        "I think it would be best just to use png for simlicity, but choose whatever you prefer.\n",
        "Other file formats are not accepted.\n",
        "\n",
        "## Resize and normalize the image\n",
        "\n",
        "Required format: `img_size = (224, 224)`\n",
        "\n",
        "What's inputted to the model must be 224 times 224 pixels, not more, not less. \n",
        "\n",
        "Also, the model only takes pixel values between 0 and 1.\n",
        "\n",
        "Below, you can find a proposal for doing something similar. I adapted this from code generated by ChatGPT. Please adapt to your needs.\n",
        "\n",
        "```javascript\n",
        "// Load the png image\n",
        "// Probably just use \"waste\" \n",
        "const image = new Image();\n",
        "image.src = \"path/to/image.png\";\n",
        "\n",
        "// Wait for the image to load before processing it\n",
        "image.onload = function() {\n",
        "  // Create a canvas element to draw the image on\n",
        "  const canvas = document.createElement(\"canvas\");\n",
        "  canvas.width = 224;\n",
        "  canvas.height = 224;\n",
        "\n",
        "  // Draw the image on the canvas\n",
        "  const ctx = canvas.getContext(\"2d\");\n",
        "  ctx.drawImage(image, 0, 0, 224, 224);\n",
        "\n",
        "  // Convert the canvas to a TensorFlow.js tensor\n",
        "  const tensor = tf.browser.fromPixels(canvas)\n",
        "    .toFloat()\n",
        "    .expandDims();\n",
        "\n",
        "  // Normalize the tensor\n",
        "  const normalized = tensor.div(255.0);\n",
        "\n",
        "  // Use the tensor as input for your image classifier model\n",
        "  // This part is likely not needed and might not even work\n",
        "  // Perhaps exchange \"model.predict\" with \"model.execute\"\n",
        "  const prediction = model.predict(normalized);\n",
        "  // Prints out the prediction to console\n",
        "  console.log(prediction);\n",
        "};\n",
        "```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MXqjJnid0cce"
      },
      "source": [
        "# Step 7: Translate from waste type to waste bin\n",
        "\n",
        "Hopefully the previous part worked and it was possible to query the model. If that worked, we should have gotten a prediction of the class. At the time of writing, the classifier is able to distinguish between 20 classes of waste. We now need a recommendation for the disposal of each class. For this, I suggest a dictionary approach:\n",
        "\n",
        "```\n",
        "These are the classes currently used in the classifier:\n",
        "\n",
        "['aluminum_foil',\n",
        " 'apples',\n",
        " 'banana_peels',\n",
        " 'cardboard',\n",
        " 'condoms',\n",
        " 'diapers',\n",
        " 'food_waste',\n",
        " 'glass_bottle',\n",
        " 'old_books',\n",
        " 'oranges',\n",
        " 'pans',\n",
        " 'pizza_box',\n",
        " 'plastic_bags',\n",
        " 'plastic_packaging',\n",
        " 'plastic_toys',\n",
        " 'smartphone',\n",
        " 'tampons',\n",
        " 'tea_bags',\n",
        " 'tetrapack',\n",
        " 'toothbrush']\n",
        " ```\n",
        "\n",
        " ```python\n",
        " # this is how it could be done in Python\n",
        " def recommend_bin(prediction):\n",
        "    \"\"\"\n",
        "    Returns the value associated with the given key in the given dictionary.\n",
        "    Dictionary keys are waste type, values are recommended waste bin. \n",
        "    Thus, recommended waste bin is returned for the waste type.\n",
        "    \"\"\"\n",
        "\n",
        "    dictionary = {\"banana_peel\": \"biological_waste\", \"plastic_packaging\": \"plastic_waste\", \"cardboard\": \"paper_waste\"}\n",
        "    \n",
        "    return dictionary[prediction]\n",
        " ```\n",
        "\n",
        " ```javascript\n",
        " // here is the translation to JavaScript\n",
        " // it is just a suggestion, please adapt if there are mistakes in the translation\n",
        " function recommendBin(prediction) {\n",
        "  /*\n",
        "  Returns the value associated with the given key in the given dictionary.\n",
        "  Dictionary keys are waste type, values are recommended waste bin.\n",
        "  Thus, recommended waste bin is returned for the waste type.\n",
        "  */\n",
        "\n",
        "  const dictionary = {\n",
        "    \"banana_peel\": \"biological_waste\",\n",
        "    \"plastic_packaging\": \"plastic_waste\",\n",
        "    \"cardboard\": \"paper_waste\"\n",
        "  };\n",
        "\n",
        "  return dictionary[prediction];\n",
        "}\n",
        "```\n",
        "\n",
        "The remaining classes must be added (specified above) and the correct waste bins need to be set (see work from the UserExperience team). Subsequently, the function needs to be integrated with the rest of the pipeline.\n",
        "\n",
        "Finally, some output needs to be made. I suggest class, recommended waste and maybe confidence. This is optional, however.\n",
        "\n",
        "Consider adding a button for the user to label the image as misclassified."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
